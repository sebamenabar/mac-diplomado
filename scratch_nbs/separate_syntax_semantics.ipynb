{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:27:59.598614Z",
     "start_time": "2019-08-31T01:27:59.570530Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:28:37.785357Z",
     "start_time": "2019-08-31T01:28:36.969162Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:28:51.261746Z",
     "start_time": "2019-08-31T01:28:51.233433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:29:21.076502Z",
     "start_time": "2019-08-31T01:29:21.031068Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## UTILS\n",
    "\n",
    "def load_vocab(cfg):\n",
    "    def invert_dict(d):\n",
    "        return {v: k for k, v in d.items()}\n",
    "\n",
    "    with open(os.path.join(cfg.DATASET.DATA_DIR, 'dic.pkl'), 'rb') as f:\n",
    "        dictionaries = pickle.load(f)\n",
    "    vocab = {}\n",
    "    vocab['question_token_to_idx'] = dictionaries[\"word_dic\"]\n",
    "    vocab['answer_token_to_idx'] = dictionaries[\"answer_dic\"]\n",
    "    vocab['question_token_to_idx']['pad'] = 0\n",
    "    vocab['question_idx_to_token'] = invert_dict(vocab['question_token_to_idx'])\n",
    "    vocab['answer_idx_to_token'] = invert_dict(vocab['answer_token_to_idx'])\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def init_modules(modules, w_init='kaiming_uniform'):\n",
    "    if w_init == \"normal\":\n",
    "        _init = init.normal_\n",
    "    elif w_init == \"xavier_normal\":\n",
    "        _init = init.xavier_normal_\n",
    "    elif w_init == \"xavier_uniform\":\n",
    "        _init = init.xavier_uniform_\n",
    "    elif w_init == \"kaiming_normal\":\n",
    "        _init = init.kaiming_normal_\n",
    "    elif w_init == \"kaiming_uniform\":\n",
    "        _init = init.kaiming_uniform_\n",
    "    elif w_init == \"orthogonal\":\n",
    "        _init = init.orthogonal_\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    for m in modules:\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "            _init(m.weight)\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "        if isinstance(m, (nn.LSTM, nn.GRU)):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'bias' in name:\n",
    "                    nn.init.zeros_(param)\n",
    "                elif 'weight' in name:\n",
    "                    _init(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControlUnit(nn.Module):\n",
    "    def __init__(self,\n",
    "                 module_dim,\n",
    "                 max_step=4,\n",
    "                 separate_syntax_semantics=False,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(module_dim, 1)\n",
    "        # self.control_input = nn.Sequential(nn.Linear(module_dim, module_dim),\n",
    "        #                                    nn.Tanh())\n",
    "\n",
    "        self.control_input_u = nn.ModuleList()\n",
    "        for i in range(max_step):\n",
    "            self.control_input_u.append(nn.Linear(module_dim, module_dim))\n",
    "\n",
    "        self.module_dim = module_dim\n",
    "        self.separate_syntax_semantics = separate_syntax_semantics\n",
    "\n",
    "    def mask(self, question_lengths, device):\n",
    "        max_len = max(question_lengths)\n",
    "        mask = torch.arange(max_len, device=device).expand(len(question_lengths), int(max_len)) < question_lengths.unsqueeze(1)\n",
    "        mask = mask.float()\n",
    "        ones = torch.ones_like(mask)\n",
    "        mask = (ones - mask) * (1e-30)\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_by_length(x, lengths, device=None):\n",
    "        lengths = torch.as_tensor(lengths, dtype=torch.float32, device=device)\n",
    "        max_len = max(lengths)\n",
    "        mask = torch.arange(max_len, device=device).expand(len(lengths), int(max_len)) < lengths.unsqueeze(1)\n",
    "        mask = mask.float().unsqueeze(2)\n",
    "        x_masked = x * mask + (1 - 1 / mask)\n",
    "\n",
    "        return x_masked\n",
    "\n",
    "    def forward(self, question, context, question_lengths, step):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question: external inputs to control unit (the question vector).\n",
    "                [batchSize, ctrlDim]\n",
    "            context: the representation of the words used to compute the attention.\n",
    "                [batchSize, questionLength, ctrlDim]\n",
    "            control: previous control state\n",
    "            question_lengths: the length of each question.\n",
    "                [batchSize]\n",
    "            step: which step in the reasoning chain\n",
    "        \"\"\"\n",
    "        # compute interactions with question words\n",
    "        # question = self.control_input(question)\n",
    "        if self.separate_syntax_semantics:\n",
    "            syntactics, semantics = context\n",
    "        else:\n",
    "            syntactics, semantics = context, context\n",
    "\n",
    "        question = self.control_input_u[step](question)\n",
    "\n",
    "        newContControl = question\n",
    "        newContControl = torch.unsqueeze(newContControl, 1)\n",
    "        interactions = newContControl * syntactics\n",
    "\n",
    "        # compute attention distribution over words and summarize them accordingly\n",
    "        logits = self.attn(interactions)\n",
    "\n",
    "        logits = self.mask_by_length(logits, question_lengths, device=syntactics.device)\n",
    "        attn = F.softmax(logits, 1)\n",
    "\n",
    "        # apply soft attention to current context words\n",
    "        next_control = (attn * semantics).sum(1)\n",
    "\n",
    "        return next_control\n",
    "\n",
    "\n",
    "class ReadUnit(nn.Module):\n",
    "    def __init__(self, module_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.concat = nn.Linear(module_dim * 2, module_dim)\n",
    "        self.concat_2 = nn.Linear(module_dim, module_dim)\n",
    "        self.attn = nn.Linear(module_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        self.kproj = nn.Linear(module_dim, module_dim)\n",
    "        self.mproj = nn.Linear(module_dim, module_dim)\n",
    "\n",
    "        self.activation = nn.ELU()\n",
    "        self.module_dim = module_dim\n",
    "\n",
    "    def forward(self, memory, know, control, memDpMask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            memory: the cell's memory state\n",
    "                [batchSize, memDim]\n",
    "\n",
    "            know: representation of the knowledge base (image).\n",
    "                [batchSize, kbSize (Height * Width), memDim]\n",
    "\n",
    "            control: the cell's control state\n",
    "                [batchSize, ctrlDim]\n",
    "\n",
    "            memDpMask: variational dropout mask (if used)\n",
    "                [batchSize, memDim]\n",
    "        \"\"\"\n",
    "        ## Step 1: knowledge base / memory interactions\n",
    "        # compute interactions between knowledge base and memory\n",
    "        know = self.dropout(know)\n",
    "        if memDpMask is not None:\n",
    "            if self.training:\n",
    "                memory = applyVarDpMask(memory, memDpMask, 0.85)\n",
    "        else:\n",
    "            memory = self.dropout(memory)\n",
    "        know_proj = self.kproj(know)\n",
    "        memory_proj = self.mproj(memory)\n",
    "        memory_proj = memory_proj.unsqueeze(1)\n",
    "        interactions = know_proj * memory_proj\n",
    "\n",
    "        # project memory interactions back to hidden dimension\n",
    "        interactions = torch.cat([interactions, know_proj], -1)\n",
    "        interactions = self.concat(interactions)\n",
    "        interactions = self.activation(interactions)\n",
    "        interactions = self.concat_2(interactions)\n",
    "\n",
    "        ## Step 2: compute interactions with control\n",
    "        control = control.unsqueeze(1)\n",
    "        interactions = interactions * control\n",
    "        interactions = self.activation(interactions)\n",
    "\n",
    "        ## Step 3: sum attentions up over the knowledge base\n",
    "        # transform vectors to attention distribution\n",
    "        interactions = self.dropout(interactions)\n",
    "        attn = self.attn(interactions).squeeze(-1)\n",
    "        attn = F.softmax(attn, 1)\n",
    "\n",
    "        # sum up the knowledge base according to the distribution\n",
    "        attn = attn.unsqueeze(-1)\n",
    "        read = (attn * know).sum(1)\n",
    "\n",
    "        return read\n",
    "\n",
    "\n",
    "class WriteUnit(nn.Module):\n",
    "    def __init__(self, module_dim, rtom=True):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(module_dim * 2, module_dim)\n",
    "        self.rtom = rtom\n",
    "        \n",
    "    def forward(self, memory, info):\n",
    "        if self.rtom:\n",
    "            newMemory = info\n",
    "        else:\n",
    "            newMemory = torch.cat([memory, info], -1)\n",
    "            newMemory = self.linear(newMemory)\n",
    "\n",
    "        return newMemory\n",
    "\n",
    "\n",
    "class MACUnit(nn.Module):\n",
    "    def __init__(self, units_cfg, module_dim=512, max_step=4):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.control = ControlUnit(\n",
    "            **{\n",
    "                'module_dim': module_dim,\n",
    "                'max_step': max_step,\n",
    "                **units_cfg.common,\n",
    "                **units_cfg.control_unit\n",
    "            })\n",
    "        self.read = ReadUnit(\n",
    "            **{\n",
    "                'module_dim': module_dim,\n",
    "                **units_cfg.common,\n",
    "                **units_cfg.read_unit,\n",
    "            })\n",
    "        self.write = WriteUnit(\n",
    "            **{\n",
    "                'module_dim': module_dim,\n",
    "                **units_cfg.common,\n",
    "                **units_cfg.write_unit,\n",
    "            })\n",
    "\n",
    "        self.initial_memory = nn.Parameter(torch.zeros(1, module_dim))\n",
    "\n",
    "        self.module_dim = module_dim\n",
    "        self.max_step = max_step\n",
    "\n",
    "    def zero_state(self, batch_size, question):\n",
    "        initial_memory = self.initial_memory.expand(batch_size, self.module_dim)\n",
    "        initial_control = question\n",
    "\n",
    "        if self.cfg.TRAIN.VAR_DROPOUT:\n",
    "            memDpMask = generateVarDpMask((batch_size, self.module_dim), 0.85)\n",
    "        else:\n",
    "            memDpMask = None\n",
    "\n",
    "        return initial_control, initial_memory, memDpMask\n",
    "\n",
    "    def forward(self, context, question, knowledge, question_lengths):\n",
    "        batch_size = question.size(0)\n",
    "        control, memory, memDpMask = self.zero_state(batch_size, question)\n",
    "\n",
    "        for i in range(self.max_step):\n",
    "            # control unit\n",
    "            control = self.control(question, context, question_lengths, i)\n",
    "            # read unit\n",
    "            info = self.read(memory, knowledge, control, memDpMask)\n",
    "            # write unit\n",
    "            memory = self.write(memory, info)\n",
    "\n",
    "        return memory\n",
    "\n",
    "\n",
    "class InputUnit(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 wordvec_dim=300,\n",
    "                 rnn_dim=512,\n",
    "                 module_dim=512,\n",
    "                 bidirectional=True,\n",
    "                 separate_syntax_semantics=False,\n",
    "                 separate_syntax_semantics_embeddings=False,\n",
    "                ):\n",
    "        super(InputUnit, self).__init__()\n",
    "\n",
    "        self.dim = module_dim\n",
    "        self.wordvec_dim = wordvec_dim\n",
    "        self.separate_syntax_semantics = separate_syntax_semantics\n",
    "        self.separate_syntax_semantics_embeddings = separate_syntax_semantics and separate_syntax_semantics_embeddings\n",
    "\n",
    "        self.stem = nn.Sequential(nn.Dropout(p=0.18),\n",
    "                                  nn.Conv2d(1024, module_dim, 3, 1, 1),\n",
    "                                  nn.ELU(),\n",
    "                                  nn.Dropout(p=0.18),\n",
    "                                  nn.Conv2d(module_dim, module_dim, kernel_size=3, stride=1, padding=1),\n",
    "                                  nn.ELU())\n",
    "\n",
    "        self.bidirectional = bidirectional\n",
    "        if bidirectional:\n",
    "            rnn_dim = rnn_dim // 2\n",
    "\n",
    "        self.encoder = nn.LSTM(wordvec_dim, rnn_dim, batch_first=True, bidirectional=bidirectional)\n",
    "        if self.separate_syntax_semantics_embeddings:\n",
    "            wordvec_dim *= 2\n",
    "        self.encoder_embed = nn.Embedding(vocab_size, wordvec_dim)\n",
    "        self.embedding_dropout = nn.Dropout(p=0.15)\n",
    "        self.question_dropout = nn.Dropout(p=0.08)\n",
    "\n",
    "    def forward(self, image, question, question_len):\n",
    "        b_size = question.size(0)\n",
    "\n",
    "        # get image features\n",
    "        img = self.stem(image)\n",
    "        img = img.view(b_size, self.dim, -1)\n",
    "        img = img.permute(0,2,1)\n",
    "\n",
    "        # get question and contextual word embeddings\n",
    "        embed = self.encoder_embed(question)\n",
    "        embed = self.embedding_dropout(embed)\n",
    "        if self.separate_syntax_semantics_embeddings:\n",
    "            semantics = embed[:, :, self.wordvec_dim:]\n",
    "            embed = embed[:, :, :self.wordvec_dim]\n",
    "        else:\n",
    "            semantics = embed\n",
    "        \n",
    "        embed = nn.utils.rnn.pack_padded_sequence(embed, question_len, batch_first=True)\n",
    "        contextual_words, (question_embedding, _) = self.encoder(embed)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            question_embedding = torch.cat([question_embedding[0], question_embedding[1]], -1)\n",
    "        question_embedding = self.question_dropout(question_embedding)\n",
    "\n",
    "        contextual_words, _ = nn.utils.rnn.pad_packed_sequence(contextual_words, batch_first=True)\n",
    "        \n",
    "        if self.separate_syntax_semantics:\n",
    "            contextual_words = (contextual_words, semantics)\n",
    "        \n",
    "        return question_embedding, contextual_words, img\n",
    "\n",
    "\n",
    "class OutputUnit(nn.Module):\n",
    "    def __init__(self, module_dim=512, num_answers=28):\n",
    "        super(OutputUnit, self).__init__()\n",
    "\n",
    "        self.question_proj = nn.Linear(module_dim, module_dim)\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.15),\n",
    "                                        nn.Linear(module_dim * 2, module_dim),\n",
    "                                        nn.ELU(),\n",
    "                                        nn.Dropout(0.15),\n",
    "                                        nn.Linear(module_dim, num_answers))\n",
    "\n",
    "    def forward(self, question_embedding, memory):\n",
    "        # apply classifier to output of MacCell and the question\n",
    "        question_embedding = self.question_proj(question_embedding)\n",
    "        out = torch.cat([memory, question_embedding], 1)\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MACNetwork(nn.Module):\n",
    "    def __init__(self, cfg, vocab, num_answers=28):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        if getattr(cfg.model, 'separate_syntax_semantics') is True:\n",
    "            cfg.model.input_unit.separate_syntax_semantics = True\n",
    "            cfg.model.control_unit.separate_syntax_semantics = True\n",
    "            \n",
    "        \n",
    "        encoder_vocab_size = len(vocab['question_token_to_idx'])\n",
    "        \n",
    "        self.input_unit = InputUnit(\n",
    "            vocab_size=encoder_vocab_size,\n",
    "            **cfg.model.common,\n",
    "            **cfg.model.input_unit,\n",
    "        )\n",
    "\n",
    "        self.output_unit = OutputUnit(\n",
    "            num_answers=num_answers,\n",
    "            **cfg.model.common,\n",
    "            **cfg.model.output_unit,\n",
    "        )\n",
    "\n",
    "        self.mac = MACUnit(\n",
    "            cfg.model,\n",
    "            max_step=cfg.model.max_step,\n",
    "            **cfg.model.common,\n",
    "        )\n",
    "\n",
    "        init_modules(self.modules(), w_init=cfg.TRAIN.WEIGHT_INIT)\n",
    "        nn.init.uniform_(self.input_unit.encoder_embed.weight, -1.0, 1.0)\n",
    "        nn.init.normal_(self.mac.initial_memory)\n",
    "\n",
    "    def forward(self, image, question, question_len):\n",
    "        # get image, word, and sentence embeddings\n",
    "        question_embedding, contextual_words, img = self.input_unit(image, question, question_len)\n",
    "\n",
    "        # apply MacCell\n",
    "        memory = self.mac(contextual_words, question_embedding, img, question_len)\n",
    "\n",
    "        # get classification\n",
    "        out = self.output_unit(question_embedding, memory)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:34:28.303758Z",
     "start_time": "2019-08-31T01:34:28.265499Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = edict({\n",
    "    'GPU_ID': '-1',\n",
    "    'CUDA': False,\n",
    "    'WORKERS': 4,\n",
    "    'TRAIN': {'FLAG': True,\n",
    "    'LEARNING_RATE': 0.0001,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'MAX_EPOCHS': 25,\n",
    "    'SNAPSHOT_INTERVAL': 5,\n",
    "    'WEIGHT_INIT': 'xavier_uniform',\n",
    "    'CLIP_GRADS': True,\n",
    "    'CLIP': 8,\n",
    "    # 'MAX_STEPS': 4,\n",
    "    'EALRY_STOPPING': True,\n",
    "    'PATIENCE': 5,\n",
    "    'VAR_DROPOUT': False},\n",
    "    'DATASET': {\n",
    "        # 'DATA_DIR': '/mnt/nas2/GrimaRepo/datasets/CLEVR_v1.0/features',\n",
    "        'DATA_DIR': '/Users/sebamenabar/Documents/datasets/CLEVR/data/',\n",
    "    },\n",
    "    'model': {\n",
    "        'max_step': 4,\n",
    "        'separate_syntax_semantics': True,\n",
    "        'common': {\n",
    "            'module_dim': 256,\n",
    "        },\n",
    "        'input_unit': {\n",
    "            'wordvec_dim': 256,\n",
    "            'rnn_dim': 256, \n",
    "            'bidirectional': True,\n",
    "            'separate_syntax_semantics_embeddings': True,\n",
    "        },\n",
    "        'control_unit': {\n",
    "        },\n",
    "        'read_unit': {},\n",
    "        'write_unit': {\n",
    "            'rtom': True,\n",
    "        },\n",
    "        'output_unit': {},\n",
    "    }\n",
    "})\n",
    "\n",
    "vocab = load_vocab(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edict(a=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T01:35:49.213317Z",
     "start_time": "2019-08-31T01:35:49.168177Z"
    },
    "code_folding": [
     0,
     19
    ]
   },
   "outputs": [],
   "source": [
    "class ClevrDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, split='train'):\n",
    "\n",
    "        with open(os.path.join(data_dir, '{}.pkl'.format(split)), 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        self.img = h5py.File(os.path.join(data_dir, '{}_features.h5'.format(split)), 'r')['features'] # ['data']\n",
    "        # self.img = h5py.File(os.path.join(data_dir, '{}_features.hdf5'.format(split)), 'r')['data']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgfile, question, answer, family = self.data[index]\n",
    "        id = int(imgfile.rsplit('_', 1)[1][:-4])\n",
    "        img = torch.from_numpy(self.img[id])\n",
    "\n",
    "        return img, question, len(question), answer, family\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, lengths, answers, _ = [], [], [], []\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    max_len = max(map(lambda x: len(x[1]), batch))\n",
    "\n",
    "    questions = np.zeros((batch_size, max_len), dtype=np.int64)\n",
    "    sort_by_len = sorted(batch, key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    for i, b in enumerate(sort_by_len):\n",
    "        image, question, length, answer, family = b\n",
    "        images.append(image)\n",
    "        length = len(question)\n",
    "        questions[i, :length] = question\n",
    "        lengths.append(length)\n",
    "        answers.append(answer)\n",
    "\n",
    "    return {'image': torch.stack(images), 'question': torch.from_numpy(questions),\n",
    "            'answer': torch.LongTensor(answers), 'question_length': lengths}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ClevrDataset(cfg.DATASET.DATA_DIR, split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "                                              Kernel Shape       Output Shape  \\\n",
      "Layer                                                                           \n",
      "0_input_unit.stem.Dropout_0                              -  [8, 1024, 14, 14]   \n",
      "1_input_unit.stem.Conv2d_1               [1024, 256, 3, 3]   [8, 256, 14, 14]   \n",
      "2_input_unit.stem.ELU_2                                  -   [8, 256, 14, 14]   \n",
      "3_input_unit.stem.Dropout_3                              -   [8, 256, 14, 14]   \n",
      "4_input_unit.stem.Conv2d_4                [256, 256, 3, 3]   [8, 256, 14, 14]   \n",
      "5_input_unit.stem.ELU_5                                  -   [8, 256, 14, 14]   \n",
      "6_input_unit.Embedding_encoder_embed             [512, 90]       [8, 19, 512]   \n",
      "7_input_unit.Dropout_embedding_dropout                   -       [8, 19, 512]   \n",
      "8_input_unit.LSTM_encoder                                -         [116, 256]   \n",
      "9_input_unit.Dropout_question_dropout                    -           [8, 256]   \n",
      "10_mac.control.control_input_u.Linear_0         [256, 256]           [8, 256]   \n",
      "11_mac.control.Linear_attn                        [256, 1]         [8, 19, 1]   \n",
      "12_mac.read.Dropout_dropout                              -      [8, 196, 256]   \n",
      "13_mac.read.Dropout_dropout                              -           [8, 256]   \n",
      "14_mac.read.Linear_kproj                        [256, 256]      [8, 196, 256]   \n",
      "15_mac.read.Linear_mproj                        [256, 256]           [8, 256]   \n",
      "16_mac.read.Linear_concat                       [512, 256]      [8, 196, 256]   \n",
      "17_mac.read.ELU_activation                               -      [8, 196, 256]   \n",
      "18_mac.read.Linear_concat_2                     [256, 256]      [8, 196, 256]   \n",
      "19_mac.read.ELU_activation                               -      [8, 196, 256]   \n",
      "20_mac.read.Dropout_dropout                              -      [8, 196, 256]   \n",
      "21_mac.read.Linear_attn                           [256, 1]        [8, 196, 1]   \n",
      "22_mac.control.control_input_u.Linear_1         [256, 256]           [8, 256]   \n",
      "23_mac.control.Linear_attn                        [256, 1]         [8, 19, 1]   \n",
      "24_mac.read.Dropout_dropout                              -      [8, 196, 256]   \n",
      "25_mac.read.Dropout_dropout                              -           [8, 256]   \n",
      "26_mac.read.Linear_kproj                        [256, 256]      [8, 196, 256]   \n",
      "27_mac.read.Linear_mproj                        [256, 256]           [8, 256]   \n",
      "28_mac.read.Linear_concat                       [512, 256]      [8, 196, 256]   \n",
      "29_mac.read.ELU_activation                               -      [8, 196, 256]   \n",
      "30_mac.read.Linear_concat_2                     [256, 256]      [8, 196, 256]   \n",
      "31_mac.read.ELU_activation                               -      [8, 196, 256]   \n",
      "32_mac.read.Dropout_dropout                              -      [8, 196, 256]   \n",
      "33_mac.read.Linear_attn                           [256, 1]        [8, 196, 1]   \n",
      "34_mac.control.control_input_u.Linear_2         [256, 256]           [8, 256]   \n",
      "35_mac.control.Linear_attn                        [256, 1]         [8, 19, 1]   \n",
      "36_mac.read.Dropout_dropout                              -      [8, 196, 256]   \n",
      "37_mac.read.Dropout_dropout                              -           [8, 256]   \n",
      "38_mac.read.Linear_kproj                        [256, 256]      [8, 196, 256]   \n",
      "39_mac.read.Linear_mproj                        [256, 256]           [8, 256]   \n",
      "40_mac.read.Linear_concat                       [512, 256]      [8, 196, 256]   \n",
      "41_mac.read.ELU_activation                               -      [8, 196, 256]   \n",
      "42_mac.read.Linear_concat_2                     [256, 256]      [8, 196, 256]   \n",
      "43_mac.read.ELU_activation                               -      [8, 196, 256]   \n",
      "44_mac.read.Dropout_dropout                              -      [8, 196, 256]   \n",
      "45_mac.read.Linear_attn                           [256, 1]        [8, 196, 1]   \n",
      "46_mac.control.control_input_u.Linear_3         [256, 256]           [8, 256]   \n",
      "47_mac.control.Linear_attn                        [256, 1]         [8, 19, 1]   \n",
      "48_mac.read.Dropout_dropout                              -      [8, 196, 256]   \n",
      "49_mac.read.Dropout_dropout                              -           [8, 256]   \n",
      "50_mac.read.Linear_kproj                        [256, 256]      [8, 196, 256]   \n",
      "51_mac.read.Linear_mproj                        [256, 256]           [8, 256]   \n",
      "52_mac.read.Linear_concat                       [512, 256]      [8, 196, 256]   \n",
      "53_mac.read.ELU_activation                               -      [8, 196, 256]   \n",
      "54_mac.read.Linear_concat_2                     [256, 256]      [8, 196, 256]   \n",
      "55_mac.read.ELU_activation                               -      [8, 196, 256]   \n",
      "56_mac.read.Dropout_dropout                              -      [8, 196, 256]   \n",
      "57_mac.read.Linear_attn                           [256, 1]        [8, 196, 1]   \n",
      "58_output_unit.Linear_question_proj             [256, 256]           [8, 256]   \n",
      "59_output_unit.classifier.Dropout_0                      -           [8, 512]   \n",
      "60_output_unit.classifier.Linear_1              [512, 256]           [8, 256]   \n",
      "61_output_unit.classifier.ELU_2                          -           [8, 256]   \n",
      "62_output_unit.classifier.Dropout_3                      -           [8, 256]   \n",
      "63_output_unit.classifier.Linear_4               [256, 28]            [8, 28]   \n",
      "\n",
      "                                            Params    Mult-Adds  \n",
      "Layer                                                            \n",
      "0_input_unit.stem.Dropout_0                      -            -  \n",
      "1_input_unit.stem.Conv2d_1               2.359552M  462.422016M  \n",
      "2_input_unit.stem.ELU_2                          -            -  \n",
      "3_input_unit.stem.Dropout_3                      -            -  \n",
      "4_input_unit.stem.Conv2d_4                 590.08k  115.605504M  \n",
      "5_input_unit.stem.ELU_5                          -            -  \n",
      "6_input_unit.Embedding_encoder_embed        46.08k       46.08k  \n",
      "7_input_unit.Dropout_embedding_dropout           -            -  \n",
      "8_input_unit.LSTM_encoder                 395.264k     393.216k  \n",
      "9_input_unit.Dropout_question_dropout            -            -  \n",
      "10_mac.control.control_input_u.Linear_0    65.792k      65.536k  \n",
      "11_mac.control.Linear_attn                   257.0        256.0  \n",
      "12_mac.read.Dropout_dropout                      -            -  \n",
      "13_mac.read.Dropout_dropout                      -            -  \n",
      "14_mac.read.Linear_kproj                   65.792k      65.536k  \n",
      "15_mac.read.Linear_mproj                   65.792k      65.536k  \n",
      "16_mac.read.Linear_concat                 131.328k     131.072k  \n",
      "17_mac.read.ELU_activation                       -            -  \n",
      "18_mac.read.Linear_concat_2                65.792k      65.536k  \n",
      "19_mac.read.ELU_activation                       -            -  \n",
      "20_mac.read.Dropout_dropout                      -            -  \n",
      "21_mac.read.Linear_attn                      257.0        256.0  \n",
      "22_mac.control.control_input_u.Linear_1    65.792k      65.536k  \n",
      "23_mac.control.Linear_attn                       -        256.0  \n",
      "24_mac.read.Dropout_dropout                      -            -  \n",
      "25_mac.read.Dropout_dropout                      -            -  \n",
      "26_mac.read.Linear_kproj                         -      65.536k  \n",
      "27_mac.read.Linear_mproj                         -      65.536k  \n",
      "28_mac.read.Linear_concat                        -     131.072k  \n",
      "29_mac.read.ELU_activation                       -            -  \n",
      "30_mac.read.Linear_concat_2                      -      65.536k  \n",
      "31_mac.read.ELU_activation                       -            -  \n",
      "32_mac.read.Dropout_dropout                      -            -  \n",
      "33_mac.read.Linear_attn                          -        256.0  \n",
      "34_mac.control.control_input_u.Linear_2    65.792k      65.536k  \n",
      "35_mac.control.Linear_attn                       -        256.0  \n",
      "36_mac.read.Dropout_dropout                      -            -  \n",
      "37_mac.read.Dropout_dropout                      -            -  \n",
      "38_mac.read.Linear_kproj                         -      65.536k  \n",
      "39_mac.read.Linear_mproj                         -      65.536k  \n",
      "40_mac.read.Linear_concat                        -     131.072k  \n",
      "41_mac.read.ELU_activation                       -            -  \n",
      "42_mac.read.Linear_concat_2                      -      65.536k  \n",
      "43_mac.read.ELU_activation                       -            -  \n",
      "44_mac.read.Dropout_dropout                      -            -  \n",
      "45_mac.read.Linear_attn                          -        256.0  \n",
      "46_mac.control.control_input_u.Linear_3    65.792k      65.536k  \n",
      "47_mac.control.Linear_attn                       -        256.0  \n",
      "48_mac.read.Dropout_dropout                      -            -  \n",
      "49_mac.read.Dropout_dropout                      -            -  \n",
      "50_mac.read.Linear_kproj                         -      65.536k  \n",
      "51_mac.read.Linear_mproj                         -      65.536k  \n",
      "52_mac.read.Linear_concat                        -     131.072k  \n",
      "53_mac.read.ELU_activation                       -            -  \n",
      "54_mac.read.Linear_concat_2                      -      65.536k  \n",
      "55_mac.read.ELU_activation                       -            -  \n",
      "56_mac.read.Dropout_dropout                      -            -  \n",
      "57_mac.read.Linear_attn                          -        256.0  \n",
      "58_output_unit.Linear_question_proj        65.792k      65.536k  \n",
      "59_output_unit.classifier.Dropout_0              -            -  \n",
      "60_output_unit.classifier.Linear_1        131.328k     131.072k  \n",
      "61_output_unit.classifier.ELU_2                  -            -  \n",
      "62_output_unit.classifier.Dropout_3              -            -  \n",
      "63_output_unit.classifier.Linear_4          7.196k       7.168k  \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "                           Totals\n",
      "Total params            4.187678M\n",
      "Trainable params        4.187678M\n",
      "Non-trainable params          0.0\n",
      "Mult-Adds             580.245504M\n",
      "=====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_input_unit.stem.Dropout_0</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 1024, 14, 14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_input_unit.stem.Conv2d_1</th>\n",
       "      <td>[1024, 256, 3, 3]</td>\n",
       "      <td>[8, 256, 14, 14]</td>\n",
       "      <td>2359552.0</td>\n",
       "      <td>462422016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_input_unit.stem.ELU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256, 14, 14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_input_unit.stem.Dropout_3</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256, 14, 14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_input_unit.stem.Conv2d_4</th>\n",
       "      <td>[256, 256, 3, 3]</td>\n",
       "      <td>[8, 256, 14, 14]</td>\n",
       "      <td>590080.0</td>\n",
       "      <td>115605504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_input_unit.stem.ELU_5</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256, 14, 14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_input_unit.Embedding_encoder_embed</th>\n",
       "      <td>[512, 90]</td>\n",
       "      <td>[8, 19, 512]</td>\n",
       "      <td>46080.0</td>\n",
       "      <td>46080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_input_unit.Dropout_embedding_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 19, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_input_unit.LSTM_encoder</th>\n",
       "      <td>-</td>\n",
       "      <td>[116, 256]</td>\n",
       "      <td>395264.0</td>\n",
       "      <td>393216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_input_unit.Dropout_question_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_mac.control.control_input_u.Linear_0</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_mac.control.Linear_attn</th>\n",
       "      <td>[256, 1]</td>\n",
       "      <td>[8, 19, 1]</td>\n",
       "      <td>257.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_mac.read.Linear_kproj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_mac.read.Linear_mproj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_mac.read.Linear_concat</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>131328.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_mac.read.ELU_activation</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_mac.read.Linear_concat_2</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19_mac.read.ELU_activation</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21_mac.read.Linear_attn</th>\n",
       "      <td>[256, 1]</td>\n",
       "      <td>[8, 196, 1]</td>\n",
       "      <td>257.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22_mac.control.control_input_u.Linear_1</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23_mac.control.Linear_attn</th>\n",
       "      <td>[256, 1]</td>\n",
       "      <td>[8, 19, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_mac.read.Linear_kproj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27_mac.read.Linear_mproj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28_mac.read.Linear_concat</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29_mac.read.ELU_activation</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34_mac.control.control_input_u.Linear_2</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35_mac.control.Linear_attn</th>\n",
       "      <td>[256, 1]</td>\n",
       "      <td>[8, 19, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38_mac.read.Linear_kproj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39_mac.read.Linear_mproj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40_mac.read.Linear_concat</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41_mac.read.ELU_activation</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42_mac.read.Linear_concat_2</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43_mac.read.ELU_activation</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45_mac.read.Linear_attn</th>\n",
       "      <td>[256, 1]</td>\n",
       "      <td>[8, 196, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46_mac.control.control_input_u.Linear_3</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47_mac.control.Linear_attn</th>\n",
       "      <td>[256, 1]</td>\n",
       "      <td>[8, 19, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50_mac.read.Linear_kproj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51_mac.read.Linear_mproj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52_mac.read.Linear_concat</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53_mac.read.ELU_activation</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54_mac.read.Linear_concat_2</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_mac.read.ELU_activation</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56_mac.read.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 196, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57_mac.read.Linear_attn</th>\n",
       "      <td>[256, 1]</td>\n",
       "      <td>[8, 196, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58_output_unit.Linear_question_proj</th>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>65792.0</td>\n",
       "      <td>65536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59_output_unit.classifier.Dropout_0</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60_output_unit.classifier.Linear_1</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>131328.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61_output_unit.classifier.ELU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62_output_unit.classifier.Dropout_3</th>\n",
       "      <td>-</td>\n",
       "      <td>[8, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63_output_unit.classifier.Linear_4</th>\n",
       "      <td>[256, 28]</td>\n",
       "      <td>[8, 28]</td>\n",
       "      <td>7196.0</td>\n",
       "      <td>7168.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Kernel Shape       Output Shape  \\\n",
       "Layer                                                                       \n",
       "0_input_unit.stem.Dropout_0                          -  [8, 1024, 14, 14]   \n",
       "1_input_unit.stem.Conv2d_1           [1024, 256, 3, 3]   [8, 256, 14, 14]   \n",
       "2_input_unit.stem.ELU_2                              -   [8, 256, 14, 14]   \n",
       "3_input_unit.stem.Dropout_3                          -   [8, 256, 14, 14]   \n",
       "4_input_unit.stem.Conv2d_4            [256, 256, 3, 3]   [8, 256, 14, 14]   \n",
       "...                                                ...                ...   \n",
       "59_output_unit.classifier.Dropout_0                  -           [8, 512]   \n",
       "60_output_unit.classifier.Linear_1          [512, 256]           [8, 256]   \n",
       "61_output_unit.classifier.ELU_2                      -           [8, 256]   \n",
       "62_output_unit.classifier.Dropout_3                  -           [8, 256]   \n",
       "63_output_unit.classifier.Linear_4           [256, 28]            [8, 28]   \n",
       "\n",
       "                                        Params    Mult-Adds  \n",
       "Layer                                                        \n",
       "0_input_unit.stem.Dropout_0                NaN          NaN  \n",
       "1_input_unit.stem.Conv2d_1           2359552.0  462422016.0  \n",
       "2_input_unit.stem.ELU_2                    NaN          NaN  \n",
       "3_input_unit.stem.Dropout_3                NaN          NaN  \n",
       "4_input_unit.stem.Conv2d_4            590080.0  115605504.0  \n",
       "...                                        ...          ...  \n",
       "59_output_unit.classifier.Dropout_0        NaN          NaN  \n",
       "60_output_unit.classifier.Linear_1    131328.0     131072.0  \n",
       "61_output_unit.classifier.ELU_2            NaN          NaN  \n",
       "62_output_unit.classifier.Dropout_3        NaN          NaN  \n",
       "63_output_unit.classifier.Linear_4      7196.0       7168.0  \n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MACNetwork(cfg=cfg, vocab=vocab)\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "b = next(iter(loader))\n",
    "\n",
    "summary(model, b['image'], b['question'], b['question_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
